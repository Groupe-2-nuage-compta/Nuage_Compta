{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('nuage_compta2': conda)",
   "display_name": "Python 3.6.12 64-bit ('nuage_compta2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "39eed0e051c3fed8c38804e99fa36f5491e9be6f546657249b959855ce9a7e13"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"./data/RAW/alphabet-dataset\"\n",
    "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"Y\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "IMG_SIZE = 28\n",
    "\n",
    "\n",
    "train_data = []\n",
    "\n",
    "def create_train_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for file in os.listdir(path):\n",
    "            file_array = cv2.imread(os.path.join(path, file), cv2.IMREAD_GRAYSCALE)\n",
    "            file_array = cv2.resize(file_array, (IMG_SIZE, IMG_SIZE))\n",
    "            train_data.append([file_array, class_num])\n",
    "\n",
    "create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, label in train_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "354302\n354302\n26\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"./data/CURATED/X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"./data/CURATED/y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "source": [
    "# Preparation et entrainement du modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"Y\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "pickle_in = open(\"./data/CURATED/X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open(\"./data/CURATED/y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X /255.0\n",
    "\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n  0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 265726 samples, validate on 88576 samples\n",
      "Epoch 1/10\n",
      "265726/265726 [==============================] - 28s 104us/sample - loss: 0.1323 - accuracy: 0.9628 - val_loss: 0.0674 - val_accuracy: 0.9817\n",
      "Epoch 2/10\n",
      "265726/265726 [==============================] - 26s 96us/sample - loss: 0.0539 - accuracy: 0.9849 - val_loss: 0.0504 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "265726/265726 [==============================] - 26s 96us/sample - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.0491 - val_accuracy: 0.9866\n",
      "Epoch 4/10\n",
      "265726/265726 [==============================] - 26s 98us/sample - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0388 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "265726/265726 [==============================] - 26s 96us/sample - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0400 - val_accuracy: 0.9905\n",
      "Epoch 6/10\n",
      "265726/265726 [==============================] - 28s 107us/sample - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "265726/265726 [==============================] - 28s 106us/sample - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0379 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "265726/265726 [==============================] - 27s 103us/sample - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0371 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "265726/265726 [==============================] - 29s 108us/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0433 - val_accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "265726/265726 [==============================] - 27s 101us/sample - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0504 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b4bee7e630>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(len(CATEGORIES)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=64, epochs=10, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/OUTPUT/cnn_model.h5')"
   ]
  },
  {
   "source": [
    "# Utilisation du modele"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./data/OUTPUT/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"Y\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "IMG_SIZE = 28\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    file_array = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    file_array = cv2.resize(file_array, (IMG_SIZE, IMG_SIZE))\n",
    "    np_image = np.array(file_array).reshape(-1, IMG_SIZE, IMG_SIZE, 1)/255.0\n",
    "    return np_image\n",
    "\n",
    "img = load('./data/RAW/alphabet-dataset/O/O-46.png')\n",
    "classes = model.predict_classes(img)\n",
    "\n",
    "print(CATEGORIES[classes[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}